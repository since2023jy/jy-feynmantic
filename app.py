import streamlit as st
import google.generativeai as genai
import json
import time
import random
import sqlite3
import pandas as pd
import plotly.express as px
from datetime import datetime

# ==========================================
# [Layer 0] Config & Styles
# ==========================================
st.set_page_config(page_title="FeynmanTic Hardcore", page_icon="âš¡", layout="centered")

st.markdown("""
    <style>
    @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');
    .stApp { background-color: #0E1117; color: #E0E0E0; font-family: 'Pretendard', monospace; }
    
    /* Chat UI - Sharp & Dark */
    .chat-message { padding: 1.2rem; border-radius: 0.5rem; margin-bottom: 1rem; line-height: 1.6; font-size: 1.05rem; }
    .chat-message.user { background-color: #161B22; border-right: 4px solid #7C4DFF; text-align: right; margin-left: 20%; }
    .chat-message.bot { background-color: #1F2428; border-left: 4px solid #FF4B4B; font-family: 'Courier New', monospace; margin-right: 5%; }
    
    /* Components */
    .gate-badge { font-size: 0.75rem; padding: 4px 10px; border-radius: 20px; background: #21262D; color: #888; border: 1px solid #333; margin-right: 5px; }
    .gate-active { background: rgba(255, 75, 75, 0.15); color: #FF4B4B; border-color: #FF4B4B; font-weight: bold; box-shadow: 0 0 8px rgba(255, 75, 75, 0.2); }
    .gate-insight { background: rgba(255, 215, 0, 0.15); color: #FFD700; border-color: #FFD700; font-weight: bold; }
    
    .stButton button { width: 100%; border-radius: 8px; font-weight: bold; }
    .stTextInput input { background-color: #0d1117 !important; color: #fff !important; border: 1px solid #30363d !important; }
    </style>
""", unsafe_allow_html=True)

# ==========================================
# [Layer 1] The Brain (System Prompts) - ì—¬ê¸°ê°€ í•µì‹¬!
# ==========================================

# 1. ì†Œí¬ë¼í…ŒìŠ¤ ì—”ì§„ (ë§¤ìš´ë§›)
SOCRATIC_SYS = """
[Role]
ë‹¹ì‹ ì€ 'íŒŒì¸ë§Œí‹± ë…¼ë¦¬ ê²€ì¦ê´€'ì…ë‹ˆë‹¤. ì¹œì ˆí•œ AI ë¹„ì„œê°€ ì•„ë‹™ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§€ì  í—ˆì˜ì‹¬ì„ ë¶€ìˆ˜ê³ , ì§„ì§œ ì´í•´í–ˆëŠ”ì§€ ê²€ì¦í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.

[Rules]
1. **ì ˆëŒ€ ë¨¼ì € ì„¤ëª…í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.** ì‚¬ìš©ìê°€ ì„¤ëª…í•˜ê²Œ ë§Œë“œì‹­ì‹œì˜¤.
2. **ëª¨í˜¸í•œ ë‹¨ì–´ ê¸ˆì§€:** "ëŒ€ì¶© ê·¸ëŸ° ê±°", "ëŠë‚Œ", "ë³µì¡í•œ ì‹œìŠ¤í…œ" ê°™ì€ ë‹¨ì–´ë¥¼ ì“°ë©´ ì¦‰ì‹œ ì§€ì í•˜ì‹­ì‹œì˜¤.
3. **ë°˜ë§/ì¡´ëŒ“ë§:** ëƒ‰ì² í•˜ê³  ê±´ì¡°í•œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "ê·¸ê±´ ë¹„ìœ ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤. ë‹¤ì‹œ.")
4. **Format:** ë°˜ë“œì‹œ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤.
   { "decision": "PASS" | "FAIL", "response": "ê²€ì¦ê´€ì˜ ë‚ ì¹´ë¡œìš´ í”¼ë“œë°±" }

[Gates Logic]
- Gate 1 (Definition): ì „ë¬¸ ìš©ì–´ ê¸ˆì§€. 5ì‚´ ì•„ì´ë„ ì•Œ ìˆ˜ ìˆëŠ” 'ë¬¼ë¦¬ì /ì§ê´€ì  ë¹„ìœ 'ë¥¼ ìš”êµ¬í•˜ì‹­ì‹œì˜¤.
- Gate 2 (Mechanism): 'ì™œ?'ë¥¼ ì§‘ìš”í•˜ê²Œ ë¬¼ìœ¼ì‹­ì‹œì˜¤. Aì—ì„œ Bë¡œ ê°€ëŠ” ì¸ê³¼ê´€ê³„ë¥¼ ì„¤ëª… ëª»í•˜ë©´ íƒˆë½ì‹œí‚¤ì‹­ì‹œì˜¤.
- Gate 3 (Falsification): ë°˜ì¦ ì‚¬ë¡€(Edge Case)ë¥¼ ì œì‹œí•˜ê³  ë°©ì–´í•˜ê²Œ í•˜ì‹­ì‹œì˜¤.
"""

# 2. ì¸ì‚¬ì´íŠ¸ ì—”ì§„ (Gate 4)
INSIGHT_SYS = """
[Role]
ë‹¹ì‹ ì€ 'ì² í•™ì  ë™ë°˜ì'ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìê°€ íŒ©íŠ¸ ê²€ì¦(Gate 1~3)ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì¹­ì°¬í•´ì£¼ê³ , ê·¸ë“¤ì˜ **'ê´€ì (View)'**ì„ ë¬¼ìœ¼ì‹­ì‹œì˜¤.

[Mission]
"íŒ©íŠ¸ëŠ” ì™„ë²½í•©ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì´ ì£¼ì œì— ëŒ€í•œ ë‹¹ì‹ ë§Œì˜ 'í•œ ì¤„ ì •ì˜'ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?"ë¼ê³  ì •ì¤‘í•˜ê²Œ ë¬¼ìœ¼ì‹­ì‹œì˜¤.
"""

# 3. ì ìˆ˜ ë° ìš”ì•½ (Artifact)
SCORE_SYS = """
ë‹¹ì‹ ì€ 'ì§€ì‹ íë ˆì´í„°'ì…ë‹ˆë‹¤.
ëŒ€í™”ë¥¼ ë¶„ì„í•´ 4ê°€ì§€ ì§€í‘œ(0~100)ë¡œ í‰ê°€í•˜ê³ , ì‚¬ìš©ìì˜ í†µì°°ì„ ìš”ì•½í•˜ì‹­ì‹œì˜¤.
JSON: { "clarity": 0, "causality": 0, "defense": 0, "originality": 0, "total_score": 0, "user_insight_summary": "..." }
"""

# ==========================================
# [Layer 2] Connection Logic (Auto-Detect)
# ==========================================
def find_working_model(api_key):
    try:
        genai.configure(api_key=api_key)
        models = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
        for m in models:
            try:
                model = genai.GenerativeModel(m)
                model.generate_content("Test")
                return m
            except: continue
        return None
    except: return None

def call_gemini(api_key, sys, user, model_name):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name, system_instruction=sys, generation_config={"response_mime_type": "application/json"})
        res = model.generate_content(user)
        return json.loads(res.text)
    except Exception as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¼ë„ ë°˜í™˜í•˜ëŠ” ì•ˆì „ì¥ì¹˜
        return {"decision": "FAIL", "response": f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}

# ==========================================
# [Layer 3] App Flow
# ==========================================
if "mode" not in st.session_state: st.session_state.mode = "HOME"
if "gate" not in st.session_state: st.session_state.gate = 0
if "messages" not in st.session_state: st.session_state.messages = []
if "auto_model" not in st.session_state: st.session_state.auto_model = None

with st.sidebar:
    st.title("âš¡ FeynmanTic V12")
    st.caption("Hardcore Logic Engine")
    api_key = st.text_input("Google API Key", type="password")
    
    if api_key and not st.session_state.auto_model:
        if st.button("ğŸ”— ì—”ì§„ ì‹œë™ (Connect)"):
            with st.spinner("ê²€ì¦ê´€ì„ í˜¸ì¶œí•˜ëŠ” ì¤‘..."):
                found = find_working_model(api_key)
                if found:
                    st.session_state.auto_model = found
                    st.success(f"ì—°ê²°ë¨: {found}")
                else:
                    st.error("ìœ íš¨í•œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    if st.session_state.auto_model:
        st.info(f"Engine: {st.session_state.auto_model}")
    
    if st.button("Reset"): st.session_state.clear(); st.rerun()

# --- HOME ---
if st.session_state.mode == "HOME":
    st.markdown("<br><h1 style='text-align: center;'>DISMANTLE WHAT?</h1>", unsafe_allow_html=True)
    st.caption("ì–´ì„¤í”ˆ ì§€ì‹ì€ ì—¬ê¸°ì„œ í†µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    if st.session_state.auto_model:
        col1, col2 = st.columns(2)
        if col1.button("ğŸ”¥ Daily: ë¹„íŠ¸ì½”ì¸"): 
            st.session_state.topic="ë¹„íŠ¸ì½”ì¸"; st.session_state.mode="CHAT"; st.session_state.gate=1
            st.session_state.messages = [{"role":"assistant", "content": "ë¹„íŠ¸ì½”ì¸ì„ ì„ íƒí–ˆêµ°ìš”. \n\në¨¼ì € **'ë¹„íŠ¸ì½”ì¸'ì´ ë¬´ì—‡ì¸ì§€ ì •ì˜**í•˜ì‹­ì‹œì˜¤. \në‹¨, **'ê°€ìƒí™”í', 'ë¸”ë¡ì²´ì¸' ê°™ì€ ì „ë¬¸ ìš©ì–´ëŠ” ê¸ˆì§€**ì…ë‹ˆë‹¤. 5ì‚´ ì•„ì´ì—ê²Œ ì„¤ëª…í•˜ë“¯ ë¹„ìœ ë¥¼ ë“œì‹­ì‹œì˜¤."}]
            st.rerun()
            
        if col2.button("ğŸŒŒ Daily: ì—”íŠ¸ë¡œí”¼"): 
            st.session_state.topic="ì—”íŠ¸ë¡œí”¼"; st.session_state.mode="CHAT"; st.session_state.gate=1
            st.session_state.messages = [{"role":"assistant", "content": "ì—”íŠ¸ë¡œí”¼ë¼... ì–´ë ¤ìš´ ì£¼ì œêµ°ìš”. \n\nìˆ˜ì‹ ì“°ì§€ ë§ê³  ì„¤ëª…í•´ ë³´ì„¸ìš”. **ë°© ì²­ì†Œë¥¼ ì•ˆ í•˜ë©´ ë°©ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?** ê±°ê¸°ì„œë¶€í„° ì •ì˜ë¥¼ ì‹œì‘í•˜ì‹­ì‹œì˜¤."}]
            st.rerun()
    else:
        st.warning("ğŸ‘ˆ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ ì—”ì§„ ì‹œë™ì„ ê±°ì‹­ì‹œì˜¤.")

# --- CHAT ---
elif st.session_state.mode == "CHAT":
    # Gate Progress
    gates = ["1.Definition", "2.Mechanism", "3.Falsification", "4.Insight"]
    badges = ""
    for i, g in enumerate(gates, 1):
        style = "gate-active" if st.session_state.gate == i else ""
        if i == 4 and st.session_state.gate == 4: style = "gate-insight"
        badges += f"<span class='gate-badge {style}'>ğŸ”’ {g}</span>"
    st.markdown(f"<div style='text-align:center; margin-bottom:20px;'>{badges}</div>", unsafe_allow_html=True)

    # Chat History
    for msg in st.session_state.messages:
        role = "user" if msg["role"] == "user" else "bot"
        st.markdown(f"<div class='chat-message {role}'>{msg['content']}</div>", unsafe_allow_html=True)

    # Input
    if prompt := st.chat_input("ë…¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role":"user", "content":prompt})
        st.rerun()

    # AI Response
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        with st.chat_message("assistant"):
            box = st.empty()
            box.markdown("Thinking...")
            
            # Prompt Selection
            sys_prompt = SOCRATIC_SYS
            instruction = ""
            if st.session_state.gate == 1: instruction = "í˜„ì¬ ë‹¨ê³„: Gate 1 (ì •ì˜). ì „ë¬¸ ìš©ì–´ë¥¼ ì¼ëŠ”ì§€ ê°ì‹œí•˜ê³ , ì¼ìœ¼ë©´ ê°€ì°¨ì—†ì´ FAILì„ ì£¼ì‹­ì‹œì˜¤."
            elif st.session_state.gate == 2: instruction = "í˜„ì¬ ë‹¨ê³„: Gate 2 (ë©”ì»¤ë‹ˆì¦˜). 'ì™œ?'ë¼ê³  ë¬»ê³  ì¸ê³¼ê´€ê³„ë¥¼ ê²€ì¦í•˜ì‹­ì‹œì˜¤."
            elif st.session_state.gate == 3: instruction = "í˜„ì¬ ë‹¨ê³„: Gate 3 (ë°˜ì¦). ì˜ˆì™¸ ìƒí™©ì„ ì œì‹œí•˜ê³  ë°©ì–´í•˜ê²Œ í•˜ì‹­ì‹œì˜¤."
            elif st.session_state.gate == 4: sys_prompt = INSIGHT_SYS; instruction = "í˜„ì¬ ë‹¨ê³„: Gate 4 (í†µì°°). ìœ ì €ì˜ ì² í•™ì„ ë¬¼ì–´ë³´ì‹­ì‹œì˜¤."

            full_prompt = f"{sys_prompt}\n\n[System Instruction]: {instruction}\n[Topic]: {st.session_state.topic}\n[User Input]: {st.session_state.messages[-1]['content']}"
            
            res = call_gemini(api_key, sys_prompt, full_prompt, st.session_state.auto_model)
            
            # Display Streaming-like
            response_text = res.get('response', 'ì˜¤ë¥˜ ë°œìƒ')
            box.markdown(f"<div class='chat-message bot'>{response_text}</div>", unsafe_allow_html=True)
            st.session_state.messages.append({"role":"assistant", "content":response_text})

            # State Transition
            if res.get('decision') == "PASS":
                if st.session_state.gate < 4:
                    st.session_state.gate += 1
                    time.sleep(1); st.rerun()
                else:
                    st.balloons()
                    st.success("ğŸ‰ ëª¨ë“  ê´€ë¬¸ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤! ë‹¹ì‹ ì˜ ë…¼ë¦¬ëŠ” ì™„ë²½í•©ë‹ˆë‹¤.")
                    # Here could go to Artifact View
